{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prior = None\n",
    "        self.conditional_prob = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.prior = {}\n",
    "        self.conditional_prob = {}\n",
    "        \n",
    "        # Calculate prior probability of each class\n",
    "        for label in np.unique(y):\n",
    "            self.prior[label] = np.sum(y == label) / n_samples\n",
    "        \n",
    "        # Calculate conditional probability of each feature for each class\n",
    "        for label in np.unique(y):\n",
    "            X_label = X[y == label]\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature in range(n_features):\n",
    "                feature_values = np.unique(X.iloc[:, feature])\n",
    "                feature_prob = {}\n",
    "                for value in feature_values:\n",
    "                    feature_prob[value] = np.sum(X_label.iloc[:, feature] == value) / X_label.shape[0]\n",
    "                self.conditional_prob[label][feature] = feature_prob\n",
    "            \n",
    "    def predict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        y_pred = np.zeros(n_samples)\n",
    "        \n",
    "        # Calculate probability of each class for each sample\n",
    "        for i in range(n_samples):\n",
    "            posteriors = {}\n",
    "            for label in self.prior:\n",
    "                prior = np.log(self.prior[label])\n",
    "                likelihood = 0\n",
    "                for feature in range(n_features):\n",
    "                    value = X.iloc[i, feature]\n",
    "                    if value in self.conditional_prob[label][feature]:\n",
    "                        likelihood += np.log(self.conditional_prob[label][feature][value] + 1e-6)\n",
    "                    else:\n",
    "                        # If a feature value is not observed in the training data, assign it a small probability\n",
    "                        likelihood += np.log(1e-6)\n",
    "                posterior = prior + likelihood\n",
    "                posteriors[label] = posterior\n",
    "            \n",
    "            # Choose the class with the highest probability as the predicted class\n",
    "            y_pred[i] = max(posteriors, key=posteriors.get)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df=pd.read_csv(\"/kaggle/input/new-datacsv/New.csv\",na_values=\"?\" )\n",
    "df=pd.read_csv(\"./adult.csv\",na_values=\"?\" )\n",
    "df['income'].replace(['<=50K', '>50K'], [0, 1], inplace=True)\n",
    "\n",
    "\n",
    "#filling the null values with the most frequest one\n",
    "\n",
    "df.workclass.fillna('Private',inplace=True)\n",
    "# df.occupation.value_counts()\n",
    "df.occupation.fillna(\"Prof-specialty\",inplace=True)\n",
    "df[\"native-country\"].value_counts()\n",
    "df[\"native-country\"].fillna(\"United-States\",inplace=True)\n",
    "# df.isnull().sum()\n",
    "\n",
    "\n",
    "#deriving the training and testing datasets\n",
    "\n",
    "numOfDataPoints = np.shape(df)[0] \n",
    "trainingDataPoints = (int)(67/100 * numOfDataPoints)\n",
    "\n",
    "iters = 10\n",
    "totalacc = 0\n",
    "totalprec = 0\n",
    "totalrec = 0\n",
    "totalf1 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8295135872937089\n",
      "Precision =  0.617615118503917\n",
      "Recall =  0.74728084515444\n",
      "f1score =  0.6762687157904435\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters):\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    TrainingDataSet = df[:trainingDataPoints] \n",
    "    TestingDataSet = df[trainingDataPoints:]\n",
    "    TrainingX = TrainingDataSet.drop('income',axis = 1)\n",
    "    TrainingY = TrainingDataSet['income']\n",
    "    TestingX = TestingDataSet.drop('income', axis = 1)\n",
    "    TestingY = TestingDataSet['income']\n",
    "    NB  = NaiveBayes()\n",
    "    NB.fit(TrainingX, TrainingY)\n",
    "    y_pred = NB.predict(TestingX)\n",
    "    \n",
    "    #Calculating precision,accuracy,recall,f1 score\n",
    "    tpositive=0\n",
    "    tnegative=0\n",
    "    fpositive=0\n",
    "    fnegative=0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "    #     print(y_pred[i], TestingY.iloc[i])\n",
    "        y_p = y_pred[i]\n",
    "        y_a =  TestingY.iloc[i]\n",
    "        if y_p == 1:\n",
    "            if y_a == 1:\n",
    "                tpositive+=1\n",
    "            else:\n",
    "                fpositive+=1\n",
    "        else:\n",
    "            if y_a==1:\n",
    "                fnegative+=1\n",
    "            else:\n",
    "                tnegative+=1\n",
    "\n",
    "    # print(tpositive, tnegative, fpositive, fnegative)\n",
    "\n",
    "    accuracy = (tpositive + tnegative)/(tpositive + tnegative + fpositive + fnegative)\n",
    "    precision = tpositive / (tpositive + fpositive)\n",
    "    recall = tpositive/(tpositive + fnegative)\n",
    "    f1score  = (2 * precision*recall)/ (precision+recall)\n",
    "    \n",
    "    totalacc+=accuracy\n",
    "    totalprec+=precision\n",
    "    totalrec+=recall\n",
    "    totalf1+=f1score\n",
    "\n",
    "\n",
    "\n",
    "#     print(\"Accuracy = \",accuracy)\n",
    "#     print(\"Precision = \",precision)\n",
    "#     print(\"Recall = \",recall)\n",
    "#     print(\"f1score = \",f1score)\n",
    "print(\"Accuracy = \",totalacc/iters)\n",
    "print(\"Precision = \",totalprec/iters)\n",
    "print(\"Recall = \",totalrec/iters)\n",
    "print(\"f1score = \",totalf1/iters)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
